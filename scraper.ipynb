{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import bs4\n",
    "import re\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.EdgeOptions()\n",
    "# options.add_argument('headless')\n",
    "options.add_argument('inprivate')\n",
    "driver = webdriver.Edge(options= options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://qlstats.net/player/330308')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cookie screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cookie_screen(driver : selenium.webdriver):\n",
    "    '''A function to check if the given webpage is the 'accept cookies' screen.\n",
    "    Regex matches the body of the '''\n",
    "    element = driver.find_element(By.TAG_NAME, value = 'body')\n",
    "    cookie_screen = re.compile(r'.*(To continue using qlstats, you need to agree to the use of cookies.\\nAgree).*')\n",
    "    if cookie_screen.search(element.text) is None:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#press the button\n",
    "if is_cookie_screen(driver):\n",
    "    try:\n",
    "        button = driver.find_element(By.TAG_NAME, 'button')\n",
    "        button.click()\n",
    "    except:\n",
    "        \"Cookies could not be accepted, please recheck\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the player page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player name:\n",
      "FOG\n"
     ]
    }
   ],
   "source": [
    "# finding player name\n",
    "player_name = soup.select_one('h2').text\n",
    "print('Player name:\\n{}'.format(player_name))\n",
    "\n",
    "#for unavailable IDs:\n",
    "if re.match(r\"Sorry, that player wasn't found!\", player_name):\n",
    "    print(\"Player not found, can't proceed\")\n",
    "\n",
    "else:\n",
    "    pass\n",
    "    #TODO Scrape here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELSE tag here onwards\n",
    "\n",
    "- p_tab_list\n",
    "- player_info\n",
    "- games_played\n",
    "- stats\n",
    "\n",
    "The flow for gametypes is as follows:\n",
    "- Winrate\n",
    "- K/D ratio\n",
    "- Cap Ratio\n",
    "- ELO\n",
    "- B-ELO\n",
    "- Rank\n",
    "- Last Played\n",
    "- Games played\n",
    "- Favourite map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegEx Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_extractor = re.compile(r\"Win Rate: (.*) Kill Ratio: (.*) Cap Ratio: (.*) Rating: (.*) B-Rating: (.*) Rank: (.*) Last Played: (.*) Games Played: (.*) Favorite Map: (.*)\")\n",
    "winrate_extractor = re.compile(r\"([0-9]+\\.?[0-9]*).*\\((\\d+).*, ([0-9]+).*\")\n",
    "kdRatio_extractor = re.compile(r\"(\\d+\\.?\\d+) \\((\\d+).*, (\\d+).*\")\n",
    "capRatio_extractor = re.compile(r'(.*)')\n",
    "elo_extractor = re.compile(r\"([0-9]+) Â± ([0-9]+).*, ([0-9]+).*\")\n",
    "rank_extractor = re.compile(r\"([0-9]+) of ([0-9]+).*\")\n",
    "\n",
    "extractors = [winrate_extractor, kdRatio_extractor, capRatio_extractor, elo_extractor, elo_extractor, rank_extractor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Region: Europe', 'Player ID: 330308', 'Steam ID: 76561198062475631', 'Joined: 2021-04-28   16:22:30', 'Status: active']\n",
      "{'name': 'FOG', 'Region': 'Europe', 'Player ID': '330308', 'Steam ID': '76561198062475631', 'Joined': '2021-04-28   16:22:30', 'Status': 'active'}\n",
      "{'ca': 491, 'duel': 19, 'ffa': 1}\n",
      "{'ca': {'winrate': ('65.78', '323', '168'), 'kd_ratio': ('1.52', '6936', '4554'), 'cap_ratio': ('-',), 'elo': ('1408', '37', '3326'), 'b-elo': ('1211', '48', '116'), 'rank': ('257', '1515')}, 'duel': {'winrate': ('63.16', '12', '7'), 'kd_ratio': ('1.17', '261', '223'), 'cap_ratio': ('-',), 'elo': ('1505', '134', '513'), 'b-elo': '-', 'rank': ('134', '482')}, 'ffa': {'winrate': ('0.0', '0', '1'), 'kd_ratio': ('2.27', '25', '11'), 'cap_ratio': ('-',), 'elo': ('1198', '147', '3'), 'b-elo': ('1275', '84', '10'), 'rank': '-'}}\n"
     ]
    }
   ],
   "source": [
    "# parse information from the p tab\n",
    "def extract_player_info(soup):\n",
    "    p_tab_text = soup.select_one('p').text\n",
    "    p_tab_list = list(map(str.strip, p_tab_text.split(\"\\n\")))\n",
    "    p_tab_list = [x for x in p_tab_list if x != '']\n",
    "    return p_tab_list\n",
    "\n",
    "\n",
    "\n",
    "def extract_player_name_details(p_tab_list):\n",
    "    player_info = {'name' : player_name}\n",
    "    for x in p_tab_list:\n",
    "        elements = x.split(\": \")\n",
    "        player_info[elements[0]] = elements[1]\n",
    "    return player_info\n",
    "\n",
    "\n",
    "\n",
    "# # press the overall button on the player page\n",
    "# button = driver.find_element(By.CLASS_NAME, 'tab-overall')\n",
    "# button.click()\n",
    "\n",
    "def extract_game_info(soup):\n",
    "    games_played = {}\n",
    "\n",
    "    gametypes = soup.find('ul', id = 'gbtab').text\n",
    "    gametypes = [x.strip() for x in gametypes.split('\\n') if x != '']\n",
    "\n",
    "    for i in range(len(gametypes)//2):\n",
    "        t, n = gametypes[i*2], gametypes[2*i+1][1:-1]\n",
    "        games_played[t] = int(n)\n",
    "\n",
    "    games_played.pop('overall')\n",
    "    return games_played\n",
    "\n",
    "\n",
    "def parse_gametype_stats(data:tuple):\n",
    "    '''Function for parsing the stats info given a tuple of\n",
    "    - winrate\n",
    "    - cap ratio\n",
    "    - elo\n",
    "    - b-elo\n",
    "    - rank\n",
    "    -last played\n",
    "    - games played\n",
    "    - fav map\n",
    "    \n",
    "    Returns a dictionary containing parsed info and keys:\n",
    "    winrate, cap_ratio, elo (ordered-tuple as value), b-elo (ordered-tuple as value), rank (ordered-tuple as value), last_played, num_games, fav_map'''\n",
    "    ret_dict = {}\n",
    "    keys = ['winrate', 'kd_ratio', 'cap_ratio', 'elo', 'b-elo', 'rank', 'last_played', 'num_games', 'fav_map']\n",
    "    for i in range(6):\n",
    "        try:\n",
    "            ext = extractors[i]\n",
    "            to_parse = data[i]\n",
    "            ret_dict[keys[i]] = ext.search(to_parse).groups()\n",
    "        except:\n",
    "            ret_dict[keys[i]] = '-'\n",
    "    return ret_dict\n",
    "\n",
    "def parse_stats(soup, gametypes):\n",
    "    '''Parse and stores stats by gametype into a dictionary.\n",
    "    \n",
    "    Arguments: \n",
    "    - soup: the BS4 object\n",
    "    - gametypes: a list of gametypes for extracting data. This can be acquired by scraping the 'gbtab' \n",
    "    list on a player's page on QLStats.\n",
    "    \n",
    "    Returns: A dictionary with keys as gametypes and values as the stats associated with them.\n",
    "    The stats are extracted using RegEx.'''\n",
    "    stats = {}\n",
    "    # parse winrate and elo info\n",
    "    for gt in gametypes:\n",
    "        type_stats = soup.find('div', id = 'tab-{}'.format(gt)).text\n",
    "        type_stats = type_stats.split('\\n')\n",
    "        type_stats = [x.strip() for x in type_stats if x.strip() != '']\n",
    "        stats_as_string = \" \".join(type_stats)\n",
    "\n",
    "        res = stat_extractor.search(stats_as_string)\n",
    "        #there is winrate, kill ratio, cap ratio, rating, b-rating, rank, last played games played favorite map\n",
    "        stat_dict = parse_gametype_stats(res.groups())\n",
    "        stats[gt] = stat_dict\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_tab_list = extract_player_info(soup)\n",
    "player_info = extract_player_name_details(p_tab_list)\n",
    "games_played = extract_game_info(soup)\n",
    "stats = parse_stats(soup, games_played.keys())\n",
    "print(p_tab_list)\n",
    "print(player_info)\n",
    "print(games_played)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall tab just has the latest/maximal values from the other tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<table class=\"table table-hover table-condensed\">\n",
       " <thead>\n",
       " <tr>\n",
       " <th>#</th>\n",
       " <th></th>\n",
       " <th>Played</th>\n",
       " <th>Type</th>\n",
       " <th>Server</th>\n",
       " <th>Map</th>\n",
       " <th>Result</th>\n",
       " <th>Opponent</th>\n",
       " <th>Rating</th>\n",
       " <th title=\"Rating Â± Uncertainty\">Old Glicko</th>\n",
       " <th title=\"Rating / Uncertainty\">Glicko Change</th>\n",
       " </tr>\n",
       " </thead>\n",
       " <tbody>\n",
       " </tbody>\n",
       " </table>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll('table', class_= 'table table-hover table-condensed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheh\n"
     ]
    }
   ],
   "source": [
    "#click on 'more' button\n",
    "try:\n",
    "    btn = driver.find_element(By.LINK_TEXT, 'More...')\n",
    "    btn.click()\n",
    "\n",
    "    btn = driver.find_element(By.CSS_SELECTOR, '[alt=\"overall\"]')\n",
    "    btn.click()\n",
    "except:\n",
    "    print('Could not click the button')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   Unnamed: 0              Played Type  \\\n",
       " 0        view  about 10 hours ago   ca   \n",
       " 1        view  about 10 hours ago   ca   \n",
       " 2        view  about 11 hours ago   ca   \n",
       " 3        view  about 11 hours ago   ca   \n",
       " 4        view  about 11 hours ago   ca   \n",
       " 5        view  about 11 hours ago   ca   \n",
       " 6        view  about 11 hours ago   ca   \n",
       " 7        view           1 day ago   ca   \n",
       " 8        view           1 day ago   ca   \n",
       " 9        view          3 days ago   ca   \n",
       " 10       view          3 days ago   ca   \n",
       " 11       view          3 days ago   ca   \n",
       " 12       view          4 days ago   ca   \n",
       " 13       view          5 days ago   ca   \n",
       " 14       view          5 days ago   ca   \n",
       " 15       view          5 days ago   ca   \n",
       " 16       view          5 days ago   ca   \n",
       " 17       view          5 days ago   ca   \n",
       " 18       view          5 days ago   ca   \n",
       " 19       view          5 days ago   ca   \n",
       " \n",
       "                                                Server             Map  \\\n",
       " 0   (India+Singapore+UAE) Topgun's CA Server w/cro...      quarantine   \n",
       " 1   (India+Singapore+UAE) Topgun's CA Server w/cro...       servitude   \n",
       " 2   (India+Singapore+UAE) Topgun's CA Server w/cro...      almostlost   \n",
       " 3   (India+Singapore+UAE) Topgun's CA Server w/cro...          overek   \n",
       " 4   (India+Singapore+UAE) Topgun's CA Server w/cro...         trinity   \n",
       " 5   (India+Singapore+UAE) Topgun's CA Server w/cro...         trinity   \n",
       " 6   (India+Singapore+UAE) Topgun's CA Server w/cro...     campgrounds   \n",
       " 7   (India+Singapore+UAE) Topgun's CA Server w/cro...         trinity   \n",
       " 8   (India+Singapore+UAE) Topgun's CA Server w/cro...          overek   \n",
       " 9   (India+Singapore+UAE) Topgun's CA Server w/cro...      almostlost   \n",
       " 10  (India+Singapore+UAE) Topgun's CA Server w/cro...      almostlost   \n",
       " 11  (India+Singapore+UAE) Topgun's CA Server w/cro...         trinity   \n",
       " 12  (India+Singapore+UAE) Topgun's CA Server w/cro...     deadandgone   \n",
       " 13  (India+Singapore+UAE) Topgun's CA Server w/cro...     campgrounds   \n",
       " 14  (India+Singapore+UAE) Topgun's CA Server w/cro...          asylum   \n",
       " 15  (India+Singapore+UAE) Topgun's CA Server w/cro...  hiddenfortress   \n",
       " 16  (India+Singapore+UAE) Topgun's CA Server w/cro...      almostlost   \n",
       " 17  (India+Singapore+UAE) Topgun's CA Server w/cro...          overek   \n",
       " 18  (India+Singapore+UAE) Topgun's CA Server w/cro...     campgrounds   \n",
       " 19  (India+Singapore+UAE) Topgun's CA Server w/cro...          hearth   \n",
       " \n",
       "          Result      Opponent     Rating Old Glicko  Glicko Change  \n",
       " 0    9:10  (#2)          Addy  1369 Â± 33  1411 Â± 38        -4 / -1  \n",
       " 1    10:5  (#1)          Addy  1367 Â± 33  1403 Â± 39        +9 / -1  \n",
       " 2    10:9  (#1)          Addy  1367 Â± 33  1394 Â± 39        +9 / -1  \n",
       " 3    7:10  (#1)          Addy  1358 Â± 34  1392 Â± 40        +2 / -1  \n",
       " 4    8:10  (#3)      Samooker  1268 Â± 35  1399 Â± 41        -7 / -1  \n",
       " 5   8:10  (#-1)      Samooker  1268 Â± 35  1399 Â± 41        -7 / -1  \n",
       " 6    8:10  (#1)  =*=Topgun=*=  1223 Â± 33  1400 Â± 42        -1 / -1  \n",
       " 7    10:8  (#3)     HYDRAZINE  1346 Â± 51  1397 Â± 40        +2 / -1  \n",
       " 8    10:3  (#4)          Addy  1357 Â± 36  1411 Â± 41       -14 / -1  \n",
       " 9    10:6  (#1)        Hitman  1110 Â± 44  1405 Â± 40        +6 / -1  \n",
       " 10   10:6  (#1)        Hitman  1121 Â± 45  1397 Â± 40        +7 / -1  \n",
       " 11   2:10  (#1)  =*=Topgun=*=  1257 Â± 37  1390 Â± 41        +7 / -1  \n",
       " 12   10:3  (#4)          Addy  1214 Â± 49  1232 Â± 49  -21 / -1  (B)  \n",
       " 13   10:8  (#2)          Addy  1302 Â± 31  1392 Â± 34         -1 / 0  \n",
       " 14   10:5  (#2)          Addy  1295 Â± 31  1397 Â± 35         -5 / 0  \n",
       " 15   10:6  (#2)      Samooker  1242 Â± 30  1399 Â± 35         -2 / 0  \n",
       " 16   10:7  (#1)      Samooker  1244 Â± 31  1393 Â± 36         +6 / 0  \n",
       " 17   4:10  (#2)      Samooker  1235 Â± 31  1397 Â± 36         -4 / 0  \n",
       " 18   4:10  (#1)          WOLF  1248 Â± 32  1389 Â± 37        +8 / -1  \n",
       " 19   10:4  (#1)          WOLF  1108 Â± 51  1219 Â± 49  +13 / -1  (B)  ]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(driver.current_url, attrs = {'class': 'table table-hover table-condensed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut down the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58e9361bde7ca617934da376e83056db506761bdc9593ca2087fabac973f609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
